package com.mockerview.service;

import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.http.*;
import org.springframework.messaging.simp.SimpMessagingTemplate;
import org.springframework.stereotype.Service;
import org.springframework.util.LinkedMultiValueMap;
import org.springframework.util.MultiValueMap;
import org.springframework.web.client.RestTemplate;
import org.springframework.web.multipart.MultipartFile;

import java.util.HashMap;
import java.util.Map;
import java.util.Arrays;
import java.util.List;

@Slf4j
@Service
@RequiredArgsConstructor
public class RealtimeSubtitleService {

    private final SimpMessagingTemplate messagingTemplate;
    private final RestTemplate restTemplate;

    @Value("${openai.api.key}")
    private String openaiApiKey;

    private static final List<String> HALLUCINATION_PATTERNS = Arrays.asList(
        "êµ¬ë…", "ì¢‹ì•„ìš”", "ì•Œë¦¼", "ì‹œì²­", "ê°ì‚¬í•©ë‹ˆë‹¤", "ì¬ë°Œê²Œ ë³´ì…¨ë‹¤ë©´",
        "ëŒ“ê¸€", "ê³µìœ ", "ë°©ì†¡", "ë‰´ìŠ¤", "ì „í•´ë“œë ¸ìŠµë‹ˆë‹¤",
        "í†µí•©ë‰´ìŠ¤", "ë‹¤ìŒ ì£¼ì—", "ë§Œë‚˜ìš”", "ì£¼ì— ë§Œë‚˜ìš”", "ì˜ìƒ"
    );

    public void transcribeAndBroadcast(Long sessionId, Long userId, String userName, MultipartFile audio) {
        try {
            log.info("ğŸ¤ ìë§‰ ìƒì„± ì‹œì‘ - Session: {}, User: {}, Size: {} bytes", 
                sessionId, userName, audio.getSize());
            
            if (audio.getSize() < 5000) {
                log.warn("âš ï¸ ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŒ: {} bytes", audio.getSize());
                return;
            }

            String transcription = transcribeAudio(audio);
            
            if (transcription == null || transcription.trim().isEmpty()) {
                log.warn("âš ï¸ ë¹ˆ ìë§‰ ê²°ê³¼");
                return;
            }

            transcription = transcription.trim();

            if (isHallucination(transcription)) {
                log.warn("âš ï¸ í™˜ê° ê°ì§€, ìë§‰ ë¬´ì‹œ: {}", transcription);
                return;
            }

            Map<String, Object> subtitleMessage = new HashMap<>();
            subtitleMessage.put("sessionId", sessionId);
            subtitleMessage.put("userId", userId);
            subtitleMessage.put("userName", userName);
            subtitleMessage.put("text", transcription);
            subtitleMessage.put("timestamp", System.currentTimeMillis());

            messagingTemplate.convertAndSend(
                "/topic/session/" + sessionId + "/subtitle", 
                subtitleMessage
            );

            log.info("âœ… ìë§‰ ì „ì†¡ ì™„ë£Œ: {}", transcription);

        } catch (Exception e) {
            log.error("âŒ ìë§‰ ìƒì„± ì‹¤íŒ¨", e);
        }
    }

    private boolean isHallucination(String text) {
        if (text.length() < 2) {
            return true;
        }

        String lowerText = text.toLowerCase().replaceAll("\\s+", "");
        
        for (String pattern : HALLUCINATION_PATTERNS) {
            if (lowerText.contains(pattern.toLowerCase())) {
                log.info("ğŸš« í™˜ê° íŒ¨í„´ ë§¤ì¹­: '{}' in '{}'", pattern, text);
                return true;
            }
        }

        long uniqueChars = text.chars().distinct().count();
        if (text.length() > 10 && uniqueChars < 3) {
            log.info("ğŸš« ë°˜ë³µ ë¬¸ì ê°ì§€: {}", text);
            return true;
        }

        if (text.matches(".*[.ã€‚]\\s*$") && text.length() > 20) {
            log.info("ğŸš« ë¬¸ì¥ ì¢…ê²° í˜•íƒœ ê°ì§€ (ë‰´ìŠ¤/ë°©ì†¡): {}", text);
            return true;
        }

        String[] sentences = text.split("[.ã€‚!?]");
        if (sentences.length > 2) {
            log.info("ğŸš« ë³µìˆ˜ ë¬¸ì¥ ê°ì§€ (í™˜ê° ê°€ëŠ¥ì„± ë†’ìŒ): {}", text);
            return true;
        }

        return false;
    }

    private String transcribeAudio(MultipartFile audio) {
        try {
            HttpHeaders headers = new HttpHeaders();
            headers.setBearerAuth(openaiApiKey);
            headers.setContentType(MediaType.MULTIPART_FORM_DATA);

            MultiValueMap<String, Object> body = new LinkedMultiValueMap<>();
            body.add("file", audio.getResource());
            body.add("model", "whisper-1");
            body.add("language", "ko");
            body.add("temperature", "0.0");

            HttpEntity<MultiValueMap<String, Object>> requestEntity = new HttpEntity<>(body, headers);

            log.info("ğŸ“¡ Whisper API í˜¸ì¶œ (temperature=0.0)");
            
            ResponseEntity<Map> response = restTemplate.exchange(
                "https://api.openai.com/v1/audio/transcriptions",
                HttpMethod.POST,
                requestEntity,
                Map.class
            );

            if (response.getStatusCode() == HttpStatus.OK && response.getBody() != null) {
                String result = (String) response.getBody().get("text");
                log.info("ğŸ“¥ Whisper ì›ë³¸ ê²°ê³¼: '{}'", result);
                return result;
            }

            log.warn("âš ï¸ Whisper API ì‘ë‹µ ì—†ìŒ");
            return null;

        } catch (Exception e) {
            log.error("âŒ Whisper API í˜¸ì¶œ ì‹¤íŒ¨", e);
            return null;
        }
    }
}
